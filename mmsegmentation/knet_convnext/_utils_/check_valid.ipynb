{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch\n",
    "from mmcv import Config\n",
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor\n",
    "from mmseg.datasets import (build_dataloader, build_dataset)\n",
    "import mmcv\n",
    "\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "from mmseg.datasets import build_dataloader, build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import single_gpu_test\n",
    "from mmcv.runner import load_checkpoint\n",
    "from mmcv.parallel import MMDataParallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "경로 설정\n",
    "'''\n",
    "\n",
    "epoch = 'deeplabv3lplus_2_31' # csv 파일 이름\n",
    "# model과 checkpoint 설정\n",
    "cfg = Config.fromfile('/opt/ml/mmsegmentation/_MyModel/_models_/deeplabv3plus_r101b-d8_512x1024_80k_cityscapes.py')\n",
    "checkpoint_path = '/opt/ml/mmsegmentation/_MyModel/work_dirs/deeplabv3plus_r101_2/best_mIoU_epoch_31.pth'\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "아래부분은 건들지 않아도 됩니다.\n",
    "'''\n",
    "\n",
    "work_dir = '/opt/ml/mmsegmentation/_MyModel/submission'\n",
    "root='/opt/ml/input/mmseg/images'\n",
    "\n",
    "cfg.data.val.img_dir = root\n",
    "cfg.data.val.test_mode = True\n",
    "cfg.data.val.img_dir = 'images'\n",
    "cfg.data.val.split = 'splits/valid.txt'\n",
    "cfg.data.samples_per_gpu = 1\n",
    "cfg.work_dir = work_dir\n",
    "# cfg.model.decode_head.num_classes = 11\n",
    "# cfg.model.auxiliary_head.num_classes = 11\n",
    "\n",
    "cfg.optimizer_config.grad_clip = dict(max_norm=35, norm_type=2)\n",
    "cfg.model.train_cfg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 14:04:49,136 - mmseg - INFO - Loaded 654 images\n"
     ]
    }
   ],
   "source": [
    "dataset = build_dataset(cfg.data.val)\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        samples_per_gpu=1,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
      "/opt/conda/lib/python3.8/site-packages/mmseg/models/losses/cross_entropy_loss.py:225: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /opt/ml/mmsegmentation/_MyModel/work_dirs/deeplabv3plus_r101_2/best_mIoU_epoch_31.pth\n"
     ]
    }
   ],
   "source": [
    "# checkpoint path\n",
    "\n",
    "\n",
    "model = build_segmentor(cfg.model, test_cfg=cfg.get('test_cfg'))\n",
    "checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n",
    "model.CLASSES = dataset.CLASSES\n",
    "model = MMDataParallel(model.cuda(), device_ids=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 654/654, 14.6 task/s, elapsed: 45s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "output = single_gpu_test(model, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 512\n",
    "output_size = 256\n",
    "\n",
    "submission = pd.read_csv(\"/opt/ml/mmsegmentation/_MyModel/submission/sample_submission.csv\", index_col=None)\n",
    "json_dir = os.path.join(\"/opt/ml/input/data/cv_val_1.json\")\n",
    "\n",
    "check_dir = '/opt/ml/input/mmseg/valid_check'\n",
    "os.makedirs(check_dir,exist_ok=True)\n",
    "os.makedirs(check_dir+'/csv',exist_ok=True)\n",
    "os.makedirs(check_dir+'/image',exist_ok=True)\n",
    "\n",
    "\n",
    "with open(json_dir, \"r\", encoding=\"utf8\") as outfile:\n",
    "    datas = json.load(outfile)\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "# PredictionString 대입\n",
    "palette = [[0,0,0],[192,0,128],[0,128,192],[0,128,64],[128,0,0],[64,0,128],[64,0,192],[192,128,64],[192,192,128],[64,64,128],[128,0,192]]\n",
    "\n",
    "for image_id, predict in enumerate(output):\n",
    "\n",
    "    image_id = datas[\"images\"][image_id]\n",
    "    file_name = image_id[\"file_name\"]\n",
    "    \n",
    "    temp_mask = []\n",
    "    predict = predict.reshape(1, 512, 512)\n",
    "\n",
    "    mask = predict\n",
    "    temp_mask.append(mask)\n",
    "    oms = np.array(temp_mask)\n",
    "    oms = oms.reshape([oms.shape[0], input_size*input_size]).astype(int)\n",
    "    string = oms.flatten()\n",
    "\n",
    "    submission = pd.concat([submission, pd.DataFrame([{\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}])]\n",
    "                                   , ignore_index=True)\n",
    "                                   \n",
    "\n",
    "\n",
    "submission.to_csv(os.path.join(check_dir, f'csv/submission_{epoch}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batch_01_vt/0003.jpg</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>batch_01_vt/0016.jpg</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batch_01_vt/0018.jpg</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>batch_01_vt/0019.jpg</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>batch_01_vt/0022.jpg</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               image_id                                   PredictionString\n",
       "0  batch_01_vt/0003.jpg  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "1  batch_01_vt/0016.jpg  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "2  batch_01_vt/0018.jpg  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "3  batch_01_vt/0019.jpg  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "4  batch_01_vt/0022.jpg  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path  = '/opt/ml/input/data'\n",
    "path=os.path.join(check_dir, f'csv/submission_{epoch}.csv') # csv파일 경로. 필요에 따라 수정하시면 됩니다.\n",
    "test_path = dataset_path + '/cv_val_1.json'\n",
    "batch_size=16\n",
    "result=pd.read_csv(path)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names=['Backgroud',\n",
    " 'General trash',\n",
    " 'Paper',\n",
    " 'Paper pack',\n",
    " 'Metal',\n",
    " 'Glass',\n",
    " 'Plastic',\n",
    " 'Styrofoam',\n",
    " 'Plastic bag',\n",
    " 'Battery',\n",
    " 'Clothing']\n",
    "\n",
    "palette = [[0,0,0],[192,0,128],[0,128,192],[0,128,64],[128,0,0],[64,0,128],[64,0,192],[192,128,64],[192,192,128],[64,64,128],[128,0,192]]\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\"\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"COCO format\"\"\"\n",
    "    def __init__(self, data_dir, mode = 'train', transform = None):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.coco = COCO(data_dir)\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        # image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_id = self.coco.getImgIds()[index]\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        images = cv2.imread(os.path.join(dataset_path, image_infos['file_name']))\n",
    "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        images /= 255.0\n",
    "        \n",
    "        if (self.mode in ('train', 'val')):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            # Load the categories in a variable\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            # General trash = 1, ... , Cigarette = 10\n",
    "            anns = sorted(anns, key=lambda idx : idx['area'], reverse=True)\n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i]['category_id'], cats)\n",
    "                pixel_value = category_names.index(className)\n",
    "                masks[self.coco.annToMask(anns[i]) == 1] = pixel_value\n",
    "            masks = masks.astype(np.int8)\n",
    "                        \n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "            return images, masks, image_infos\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "            return images, image_infos\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.65s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                           ToTensorV2()\n",
    "                           ])\n",
    "test_dataset = CustomDataLoader(data_dir=test_path, mode='val', transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          num_workers=4,\n",
    "                                          collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images 제거\n",
    "\n",
    "import os.path as osp\n",
    "from glob import glob\n",
    "data_dir='/opt/ml/input/mmseg/valid_check/image'\n",
    "image_paths = {x for x in glob(osp.join(data_dir, '*'))}\n",
    "\n",
    "for image_path in image_paths:\n",
    "    os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n"
     ]
    }
   ],
   "source": [
    "# images 생성\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "for i,(imgs, masks, image_infos) in enumerate(test_loader):\n",
    "    temp_images = imgs\n",
    "    temp_anns = image_infos\n",
    "    temp_masks = masks\n",
    "    for j in range(len(temp_images)):\n",
    "\n",
    "        x=torch.Tensor(temp_images[j]).permute([1,2,0])*255\n",
    "        x=x.numpy().astype(np.uint8)\n",
    "        z=temp_masks[j].numpy()\n",
    "        z=list(z.flatten())\n",
    "        for k in range(len(z)):\n",
    "            z[k]=palette[int(z[k])]\n",
    "        z=torch.Tensor(z).reshape(512,512,3).numpy()\n",
    "\n",
    "        y=result['PredictionString'][i*batch_size+j].split(\" \")\n",
    "        for k in range(len(y)):\n",
    "            y[k]=palette[int(y[k])]\n",
    "        y=torch.Tensor(y).reshape(512,512,3).numpy()\n",
    "\n",
    "        temp_result=np.concatenate((x,z,y),1)\n",
    "        temp_result=Image.fromarray(temp_result.astype(np.uint8))\n",
    "        temp_result.save(os.path.join(data_dir,f\"{int(temp_anns[j]['id']):04}.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
